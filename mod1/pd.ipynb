{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/ufidon/ml/blob/main/mod1/pd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://kaggle.com/kernels/welcome?src=https://github.com/ufidon/ml/blob/main/mod1/pd.ipynb\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" /></a>\n",
    "  </td>\n",
    "</table>\n",
    "<br>\n",
    "\n",
    "\n",
    "# Two basic data structures in Pandas\n",
    "- Series: a one-dimensional labeled array holding data of any type such as\n",
    "  - integers, strings, Python objects etc.\n",
    "- DataFrame: a two-dimensional data structure that holds data like \n",
    "  - a two-dimension array \n",
    "  - or a table with rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. create series objects\n",
    "# a default RangeIndex is created\n",
    "\n",
    "s1 = pd.Series([2, 3.14, np.nan, np.inf, 'Trump']) # s1 with default integer labels, NOT conventional index\n",
    "# in s2, the name index here is confusing, label will be better\n",
    "s2 = pd.Series([2, 3.14, np.nan, np.inf, np.NINF], index=['Biden','Trump','Obama','Pense','Gates'])\n",
    "\n",
    "# create from a dictionary wo/w explicit indexes\n",
    "cs={'Mon':'Python', 'Tue':'C++', 'Wed':'C', 'Thu':'HTML', 'Fri':'Java'}\n",
    "s3 = pd.Series(data=cs)\n",
    "s4 = pd.Series(data=cs, index=['Tue','Thr'])\n",
    "\n",
    "print(f'{s1}\\n\\n{s2}\\n\\n{s3}\\n\\n{s4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{s1.dtypes} | {s2.dtypes} | {s3.dtypes} | {s4.dtypes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{s1.keys()=}\\n{s2.keys()=}\\n{s3.keys()=}\\n{s4.keys()=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access series elements by labels and traditional indexes\n",
    "print(f'{s1[4]=}  {s1.iloc[4]=}  {s1.iat[4]=}')\n",
    "print(f'{s2[\"Trump\"]=}  \\n{s2.iloc[1:3]=}  \\n{s2.iat[1]=}')\n",
    "print(f'{s3[\"Wed\"]=} \\n{s3.iloc[2:]=}  \\n{s3.iat[4]=}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. create dataframe objects\n",
    "dates = pd.date_range(\"20230115\", periods=5)\n",
    "df1 = pd.DataFrame(np.random.randn(5,4)+10, index=dates, \n",
    "                   columns=['Precipitation','Sunshine','Wind speed','Air quality'])\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "  'Morning': 25.6,\n",
    "  'Afternoon': pd.Categorical(['train','test','eval','deploy']),\n",
    "  'Evening': np.arange(3,7),\n",
    "  'Night': np.random.randint(10,20,4)\n",
    "})\n",
    "print(f'{dates}\\n\\n{df1}\\n\\n{df2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{df1.dtypes} \\n\\n{df2.dtypes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigate data\n",
    "---\n",
    "- show first or last several rows\n",
    "- convert between pandas data types and numpy data types\n",
    "- basic statistics\n",
    "- sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. view first two rows\n",
    "df1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. view last three rows\n",
    "df1.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. show indexes and columns\n",
    "print(f'{df1.index}\\n\\n{df1.columns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. to numpy darray\n",
    "# indexes and columns are removed, only data is retained\n",
    "# dataframe's most general data type is used for numpy's dtype\n",
    "npdf1 = df1.to_numpy()\n",
    "print(f'{npdf1} \\n\\n{df1.dtypes=} {npdf1.dtype=}')\n",
    "\n",
    "npdf2 = df2.to_numpy()\n",
    "print(f'{npdf2} \\n\\n{df2.dtypes=} {npdf2.dtype=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. show a quick statistic summary\n",
    "print(f'{df1.describe()} \\n\\n {df2.describe()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. transpose\n",
    "print(f'{df2}\\n\\n{df2.T}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. sort by index (axis=0) and column header (axis=1)\n",
    "print(f'{df2}\\n\\n{df2.sort_index(axis=0, ascending=False)}\\n')\n",
    "print(f'{df2.sort_index(axis=1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. sort by columns or by values\n",
    "print(f\"{df2.sort_values(by='Morning')}\\n\\n{df2.sort_values(by='Afternoon')}\\n\\n{df2.sort_values(by='Night')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select and set indexes, columns and cells\n",
    "---\n",
    "- the Python/Numpy way is intuitive\n",
    "- optimized pandas way: DataFrame.{at(),iat(),loc(),iloc()}\n",
    "  - at() and loc() are human oriented, by label\n",
    "    - [left close, right close]\n",
    "  - iat() and iloc() are python and numpy oriented, by position\n",
    "    - [left close, right open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. select a single column\n",
    "df2['Afternoon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select multiple column\n",
    "df2[['Morning', 'Night']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. select multiple rows\n",
    "df2[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a single row\n",
    "df2[2:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__select by label (index and column header)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a single row\n",
    "df1.loc['2023-01-17']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a sub region\n",
    "# pay attention: both endpoints of : are included\n",
    "df1.loc['2023-01-16':'2023-01-18', ['Precipitation', 'Sunshine']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a cell\n",
    "df1.loc['2023-01-19',['Sunshine']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or use at() to select a cell\n",
    "df1.at['2023-01-19', 'Sunshine']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Select by position__\n",
    "\n",
    "- by row and column's integer indexes\n",
    "- follow python and numpy indexing conventions\n",
    "  - left close, right open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a row\n",
    "df1.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a region\n",
    "# [left close, right open)\n",
    "df1.iloc[1:3, 0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select with list of positions\n",
    "df1.iloc[[2,4], [ 1,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a cell\n",
    "df1.iloc[3,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or use iat() to select a cell\n",
    "df1.iat[3,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Select by conditions__\n",
    "\n",
    "- or boolean indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select rows based on column conditions\n",
    "df1[(df1['Precipitation']>11) & (df1['Wind speed']<10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[df2['Afternoon'].isin(['train', 'eval'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select values\n",
    "df1[df1>10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Modify dataframes__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. add a column\n",
    "# align the data by the indexes\n",
    "pm1 = pd.Series([3.4,5.6,3.2,9.8,4.5], index=pd.date_range('2023-01-15',periods=5))\n",
    "df1['PM2.5'] = pm1\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. remove a column\n",
    "del df1['PM2.5']\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. add column with python list and numpy array\n",
    "df1['PM2.5'] = [3.4,5.6,3.2,9.8,4.5]\n",
    "df1['Oxygen'] = np.array([.256]*len(df1))\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. set values by label\n",
    "df1.at['2023-01-15','PM2.5'] = 7.7\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set values by by position\n",
    "df1.iat[0,-1] = 0.222\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. set values by conditions\n",
    "df3 = df1.copy()\n",
    "df3[df3>5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[df3>5] = np.sin(df3)\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle missing data\n",
    "---\n",
    "- np.nan (not a number) represents missing data in numpy\n",
    "  - excluded from computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = df1[df1<11]\n",
    "dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. test missing data\n",
    "dm.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. drop any rows that have missing data\n",
    "dv = dm.dropna(how='any')\n",
    "dv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. fill missing data with a default value\n",
    "dm.fillna(value=3.14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematical operations on dataframe\n",
    "---\n",
    "- missing data is excluded generally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Calculate the mean value for each column\n",
    "df1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Calculate the mean value for each row:\n",
    "df1.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. DataFrame.agg() and DataFrame.transform() applies \n",
    "# a user defined function that reduces or broadcasts its result respectively\n",
    "\n",
    "df1.agg(lambda x: x*x+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.agg(lambda x: np.mean(x)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.transform(lambda x: x*x+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. value counts\n",
    "df2['Night'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. string methods\n",
    "df2['Afternoon'].str.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape operations on dataframe\n",
    "---\n",
    "- merge such as join, concatenate\n",
    "- group\n",
    "- reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. concatenate rows\n",
    "pd.concat([df1[:2], df1[2:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate columns\n",
    "pd.concat([df1['Precipitation'], df1['PM2.5']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. grouping steps\n",
    "# - Splitting the data into groups based on some criteria\n",
    "# - Applying a function to each group independently\n",
    "# - Combining the results into a data structure\n",
    "df1['Grade'] = ['Good','Bad','Good','Bad','Bad']\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.groupby('Grade')[['PM2.5', 'Sunshine']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping by multiple columns label forms MultiIndex.\n",
    "df1.groupby(['Grade', 'Oxygen']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.groupby('Grade', observed=False).size() # observed=False also shows empty categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import and export data\n",
    "---\n",
    "- dataframe <--> popular file formats such as\n",
    "  - csv, json, html, xml\n",
    "  - ms excel, open document, hdf5\n",
    "  - sql, google bigquery,\n",
    "  - python pickle format, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data from dataframe to csv\n",
    "df1.index.name = 'Date'\n",
    "df1.to_csv('./weather.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ./weather.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read from csv\n",
    "dfr = pd.read_csv('./weather.csv', index_col='Date')\n",
    "dfr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "- [Pandas user guide](https://pandas.pydata.org/pandas-docs/stable/user_guide/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
